\documentclass{report}
\usepackage[latin1]{inputenc}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
%\usepackage{cancel}
\usepackage[top=3.5cm,left=3cm,right=3cm,bottom=2cm,foot=1cm]{geometry}
\renewcommand{\thesection}{\arabic{section}}

\title{\textbf{Stats 202} \\ Homework 3}
\author{\textbf{Joseph Marrama}}
\date{November 4, 2011}

\begin{document}
\maketitle

\section*{Problem 1}

<<>>=
N = c(100, 80, 30)
N.1.1 = c(60, 10, 0)
N.1.2 = c(40,70,30)
N.2.1 = c(80, 20, 0)
N.2.2 = c(20, 40, 0)
N.2.3 = c(0, 20, 30)

gini <- function(N){
return (1 - sum( ( N/sum(N) )^2 ))
}

G.N.1 = gini(N) - (sum(N.1.1)*gini(N.1.1) + sum(N.1.2)*gini(N.1.2))/(sum(N.1.1) + sum(N.1.2))
G.N.2 = gini(N) - (sum(N.2.1)*gini(N.2.1) + sum(N.2.2)*gini(N.2.2) + sum(N.2.3)*gini(N.2.3))/( sum(N.2.1) + sum(N.2.2) + sum(N.2.3) )
G.N.1
G.N.2
@

As you can see, G.N.2 has a higher GINI gain, so we will choose that one, that is, we will choose the second split.

\subsubsection*{b}
<<>>=
cc = 25
cc.N.1 = cc*2 + sum(N.1.1)*gini(N.1.1) + sum(N.1.2)*gini(N.1.2)
cc.N.2 = cc*3 + sum(N.2.1)*gini(N.2.1) + sum(N.2.2)*gini(N.2.2) + sum(N.2.3)*gini(N.2.3)
cc.N.1
cc.N.2
@

As you can see, the cost complexity of the tree with split one is slightly lower, so we would choose the one with that split.

\subsubsection*{c}

<<>>=
ent <- function(N){
entlog = log(N/sum(N))
# we have to replace -Infs with 0, otherwise R returns NaN
# this shouldn't affect the entropy measure, because if something
# is -Inf in entlog the value of it is 0, thus 0*-Inf in the entropy measure
# should still come out to 0
entlog[entlog == -Inf] <- 0
return (-sum ( N/sum(N) * entlog ) )
}
ent.H.1 = ent(N) - (sum(N.1.1)*ent(N.1.1) + sum(N.1.2)*ent(N.1.2))/(sum(N.1.1) + sum(N.1.2))
ent.H.2 = ent(N) - (sum(N.2.1)*ent(N.2.1) + sum(N.2.2)*ent(N.2.2) + sum(N.2.3)*ent(N.2.3))/( sum(N.2.1) + sum(N.2.2) + sum(N.2.3) )
ent.H.1
ent.H.2
@

We would choose the second split again, because it maximizes the drop in entropy from node N

\subsubsection*{d}

<<>>=
cc = 25
cc.N.1 = cc*2 + sum(N.1.1)*ent(N.1.1) + sum(N.1.2)*ent(N.1.2)
cc.N.2 = cc*3 + sum(N.2.1)*ent(N.2.1) + sum(N.2.2)*ent(N.2.2) + sum(N.2.3)*ent(N.2.3)
cc.N.1
cc.N.2
@

We would once again choose split 2, since it has a lower cost-complexity.

\subsubsection*{e}

<<>>=
mc_err <- function(N){
return (1 - max(N)/sum(N))
}
mc_err.H.1 = mc_err(N) - (sum(N.1.1)*mc_err(N.1.1) + sum(N.1.2)*mc_err(N.1.2))/(sum(N.1.1) + sum(N.1.2))
mc_err.H.2 = mc_err(N) - (sum(N.2.1)*mc_err(N.2.1) + sum(N.2.2)*mc_err(N.2.2) + sum(N.2.3)*mc_err(N.2.3))/( sum(N.2.1) + sum(N.2.2) + sum(N.2.3) )
mc_err.H.1
mc_err.H.2
@

Once again, we would choose split 2, because it has the largest drop in misclassification error.

\subsubsection*{f}

<<>>=
cc = 25
cc.N.1 = cc*2 + sum(N.1.1)*mc_err(N.1.1) + sum(N.1.2)*mc_err(N.1.2)
cc.N.2 = cc*3 + sum(N.2.1)*mc_err(N.2.1) + sum(N.2.2)*mc_err(N.2.2) + sum(N.2.3)*mc_err(N.2.3)
cc.N.1
cc.N.2
@

We would choose split 1 cause it has the lower cost-complexity.

\section*{Problem 2}

<<>>=
library('ElemStatLearn')
library('rpart')

@


\end{document}























